---
title: Unsusceptibility to the Illusion is Inherent (rwblog S6E11)
lastUpdatedDate: 2025-05-07 18:12:28.254790+00:00
publicationDate: 2023-10-21 18:12:28.254790+00:00
season: 6
---

Hello friends. It has been a rough couple weeks for me personally, not to mention, well, the world as a whole. Hopefully you are all staying safe, sane, and healthy. This will be a short issue and I am not going to bother with interstitial images.

## Software Engineers and the Illusion of Explanatory Depth

I wonder if software engineers are less susceptible to the [illusion of explanatory depth](https://www.experimental-history.com/i/57359087/the-illusion-of-explanatory-depth). The illusion of explanatory depth says that, if you ask people if they know how e.g. a toilet works, most people will confidently say yes, but if you ask them to explain it in detail, they will quickly fumble.

Personally I do not think I would be that confident saying I know how a toilet works, or really anything else in the built world around me, and I suspect most of the software engineers I know would feel likewise. Of course perhaps that’s part of the illusion — I think I don’t fall prey to the illusion, but I actually do — but I genuinely believe that if you asked me unprompted how a toilet works, I would think very hard and then admit I don’t.

Anyway the point I’m getting at here is that I wonder if unsusceptibility to the illusion is inherent to the structure of software engineering. Far more explicitly than almost any other professional discipline, software engineering is based on abstraction, where you call part of your system a black box and don’t bother thinking about how it works. How does that API you call work? Who knows! As long as the interface is correct you can work with it. So software engineers go around thinking about everything as black boxes that we don’t really understand but can interface with anyway, which is exactly the mindset you would need to avoid the illusion of explanatory depth.

As a side note: maybe this illusion is why abstraction is so important. Since we can only remember [7 (plus or minus 2) things](https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two) in short-term memory, we _need_ to just call everything a black box to be able to work with it. c.f. also [this article](https://loup-vaillant.fr/articles/source-of-readability) titled “The Source of Readability”