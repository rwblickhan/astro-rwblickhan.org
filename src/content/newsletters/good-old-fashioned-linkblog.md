---
title: Good Old Fashioned Linkblog
lastUpdatedDate: 2025-05-07
publicationDate: 2025-05-07
season: 7
---

It’s been a while since I’ve done a good-old-fashioned link blog! So here’s some things I’ve been reading recently:

- [“A cheat sheet for why using ChatGPT is not bad for the environment”](https://andymasley.substack.com/p/a-cheat-sheet-for-conversations-about): High-end estimates for ChatGPT’s energy use per query is about 3Wh, which is the same as... leaving an incandescent bulb on for 3 minutes. (And those estimates are probably off by an order of 10.) Andy Masley builds on that to argue that, *as individuals*, we shouldn’t think about the environmental impact of ChatGPT queries at all — even heavy usage is a very small percentage of household energy use in the United States. (Hannah Ritchie from *Our World in Data* [checks the numbers](https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt#_) and comes to the same conclusion.) If you find LLMs ethical and useful (and I do, for at least some usages), then you should stop worrying!
- But then why the massive data center build out? If LLM queries are so cheap, why do investors think we need *so much energy* for it? Arthur Clune has [an insightful take](https://clune.org/posts/environmental-impact-of-ai/). Normal “Google-style” use of querying is cheap. But what if we build a Panopticon that applies an LLM to every single frame of every single camera in the UK? Then we easily need a new 1GW nuclear plant! Which is horrifying — how about we don’t build the Torment Nexus, yeah?
- One last LLM link: Max Woolf [discusses](https://minimaxir.com/2025/05/llm-use/) how he’s used LLMs productively at Buzzfeed. But I’m mostly linking for this insightful comment at the end: “Two things can be true simultaneously: (a) LLM provider cost economics are too negative to return positive ROI to investors, and (b) LLMs are useful for solving problems that are meaningful and high impact, albeit not to the AGI hype that would justify point (a). This particular combination creates a frustrating gray area that requires a nuance that an ideologically split social media can no longer support gracefully.” This eloquently expresses exactly my thoughts on the topic!
- *Speed Racer* is *by far* the best film I’ve seen so far this year. Luckily there’s now an [hour-long analysis](https://youtu.be/vwh9ETdhrf4?si=RWZALObr6MbdsWCu) from video essayist Patrick H. Willems. It probably won’t convert the unconverted — I mean, at an hour long, you should probably just watch the movie — but it does a brilliant job of breaking down how the first 10 minutes elegantly prepare viewers for the formalist excess that follows.
- A proactive take from a few years ago: [“Share poems like memes”](https://joeldueck.com/share-poems-like-memes.html). An individual poem is worth (roughly) $0, so what’s the point of treating them as intellectual property? I’m not sure I completely agree — how small is small enough to share without thinking? Certainly if you wrote a book-length poem, we shouldn’t share freely, which then turns into a fuzzy logic problem — but I like the provocation.
- Alan Jacobs points out something that many folks miss: that [*The Power Broker* is not merely a critique](https://blog.ayjay.org/moses-the-roadgiver/), but instead shows the many *good* things that Robert Moses obtained, and asks whether it’s possible to have the good without the bad.
- [This article](https://tastecooking.com/not-too-sweet-or-too-sweet-to-fail/) is an interesting analysis of the use (and, increasingly, overuse) of sugar in Asian cooking, but I mostly link it because it points out that, traditionally, in most East and Southeast Asian cuisines, sugar was used more like a spice or even salt — just a hint of sugar was added at the end to unify all the flavors.
- Okay, I lied. One more article about LLMs, but this one has the title [“On Feral Library Card Catalogs, or, Aware of All Internet Traditions”](https://www.programmablemutter.com/p/on-feral-library-card-catalogs-or), so you *know* it’s worth reading. Cosma Shalizi (statistician and long-term LLM critic) proposes “Gopnikism”, a view that LLMs are not nascent intelligences but instead novel social/cultural technologies. Needless to say, I am a hardcore Gopnikist — you may recall that I have repeatedly recommended Dr Gopnik’s talk [“Large Language Models as a Cultural Technology”](https://www.youtube.com/live/k7rPtFLH6yw?si=6yv3PCLKYWIxD_2Z)! Shalizi expresses the viewpoint perhaps even better than that talk, though this is a hefty article for sure.